# NLP Powered LLaMA-3 Enabled PDF Parser

The **NLP Powered LLaMA-3 Enabled PDF Parser** is an advanced tool designed to revolutionize the way you interact with PDF documents. Combining state-of-the-art Natural Language Processing (NLP) techniques and the powerful LLaMA-3 AI model, this parser seamlessly extracts, processes, and analyzes text from PDF filesâ€”whether they are text-based or image-based.

The tool not only extracts content with high precision but also provides robust question-answering capabilities. It intelligently identifies relevant information from large documents, offering concise and context-aware responses. Whether for research, business, or academic use, this parser transforms static PDF data into actionable insights.

## Key Features
- **Dual Mode Text Extraction**: Supports both text-based and image-based PDFs for versatile data handling.  
- **Advanced NLP Integration**: Uses preprocessing and tokenization to enhance text understanding.  
- **LLaMA-3 AI Integration**: Enables natural language querying with precise, context-aware answers.  
- **Chunking and Optimization**: Efficiently handles large documents by splitting and processing manageable chunks.  
- **User-Friendly Interface**: Simplifies PDF file selection and interaction via a straightforward GUI.

This tool is perfect for anyone looking to harness the power of AI to turn static PDFs into a dynamic and interactive knowledge source.

---

## Use Cases
- Quickly extract and analyze information from lengthy PDF reports.
- Ask questions about a document to retrieve specific answers or summaries.
- Turn static PDF documents into interactive, dynamic knowledge resources.
- Streamline research, business analysis, or academic studies with automated data parsing.

---

## Features

- Upload any PDF (text-based or image-based).
- Extracts text from the PDF using OCR and preprocessing.
- Interact via a GUI to ask questions about the PDF content.
- Answers are generated using a LLaMA-3.2 model through the Hugging Face API.

---

## Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/GLCRealm/pdf-question-assistant.git
   cd pdf-question-assistant
   ```

2. Install the required dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Ensure that **Poppler** is installed on your system (needed for image-based PDFs):
   - On **Linux**:
     ```bash
     sudo apt install poppler-utils
     ```
   - On **MacOS** (using Homebrew):
     ```bash
     brew install poppler
     ```
   - On **Windows**:
     - Download Poppler from [Poppler for Windows](https://blog.alivate.com.au/poppler-windows/).
     - Add the `bin` folder to your system's PATH.

---

## Usage

1. Run the application:
   ```bash
   python GUI.py
   ```

2. Use the interface to:
   - Upload a PDF file.
   - Enter your question in the input field.
   - View the response generated by the LLaMA-3.2 model.

---

## Important Note

You need a Hugging Face API key to use this project. Replace the placeholder API with your own API key in the code:

- **`GUI.py`**
- **`functions.py`**

You can obtain an API key by signing up on the [Hugging Face website](https://huggingface.co).

---

## Dependencies

This project uses the following dependencies:

- Python 3.8 or higher
- PyPDF2
- pdf2image
- pytesseract
- transformers
- requests
- tkinter
- Poppler (external dependency)

---

## Contributing

Contributions are welcome! Feel free to fork this repository and submit pull requests to add new features or bug fixes.

---
